{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a6e9c5",
   "metadata": {},
   "source": [
    "# Support Vector Machine Predictive Model for EDTA QC Evaluation: Part 2 – Model Optimization\n",
    "\n",
    "We will build a **Support Vector Machine** (SVM) classifier using **scikit-learn**. Two datasets (training and unknown) are used for modeling. The training dataset contains experimental data from healthy donors (described in the current manuscript: https://........). The unknown dataset contains experimental samples from healthy donors and colorectal carcinoma donors (Slyskova et al. 2015: https://pubmed.ncbi.nlm.nih.gov/24585457/). The SVM will predict blood sample quality from EDTA tubes (normal or altered gene expression) for downstream gene expression analysis.\n",
    "\n",
    "Contents:\n",
    "- **Module Imports**\n",
    "\n",
    "- **Prediction on Unseen Data and Optimalization of the Decision Boundary**\n",
    "    - Importing data\n",
    "    - Importing joblib libraries\n",
    "    - Extracting data and pre-processing them\n",
    "    - Predictions\n",
    "    - Adjusting the decision threshold\n",
    "    - Evaluation and visualization of the decision boundary\n",
    "    - Key hyperparameters\n",
    "    - Analyzing threshold ranges without changing FNR and FPR\n",
    "    - Determining FNR and threshold ranges for reliable predictions\n",
    "    - Selecting the decision threshold based on FNR\n",
    "    - Built-in data and final outcome from EDTA_QC testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbcd31",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bac660",
   "metadata": {},
   "source": [
    "#### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792a1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca126153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup paths relative to project root ──\n",
    "cwd = Path().cwd()\n",
    "ROOT = cwd\n",
    "while not (ROOT / \"README.md\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "  \n",
    "DATA_DIR   = ROOT / \"data\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "\n",
    "MODEL_VERSION = \"v8_2025-11-27\"\n",
    "TRAIN_DATA_PATH   = DATA_DIR / \"train_165_data.csv\"\n",
    "TEST1_DATA_PATH    = DATA_DIR / \"test1_data.csv\"\n",
    "TEST2_DATA_PATH    = DATA_DIR / \"test2_data.csv\"\n",
    "UNKNOWN_DATA_PATH    = DATA_DIR / \"unknown_only.csv\"\n",
    "\n",
    "PIPELINE_PATH = MODELS_DIR / \"final_pipeline_prob_v8_2025-11-27.joblib\"\n",
    "# ── End setup ──\n",
    "\n",
    "# ── Notebook outputs folder ──\n",
    "NB_OUTPUT = ROOT / \"notebooks\" / \"outputs_from_notebooks\"\n",
    "NB_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "# ── End notebook outputs setup ──"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531da14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"train_165\": TRAIN_DATA_PATH,\n",
    "    \"test1\": TEST1_DATA_PATH,\n",
    "    \"test2\": TEST2_DATA_PATH,\n",
    "    \"unknown\": UNKNOWN_DATA_PATH\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcbbaa",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dccdeb",
   "metadata": {},
   "source": [
    "#### **Optimalization of the Decision Boundary and Prediction on Unseen Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7e469",
   "metadata": {},
   "source": [
    "#### Task 1: Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32721d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "samples = {}\n",
    "\n",
    "for key, path in paths.items():\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    if \"sample\" in data.columns:\n",
    "        samples[key] = data[\"sample\"]\n",
    "        dfs[key] = data.drop(columns=\"sample\")\n",
    "    else:\n",
    "        samples[key] = data.index.astype(str)\n",
    "        dfs[key] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0849cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_165_df   = dfs[\"train_165\"]\n",
    "test1_df   = dfs[\"test1\"]\n",
    "test2_df   = dfs[\"test2\"]\n",
    "unknown_df= dfs[\"unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64dcbc",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4c35c",
   "metadata": {},
   "source": [
    "#### Task 2: Importing joblib libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ecb0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load(PIPELINE_PATH)\n",
    "\n",
    "scaler = pipeline.named_steps['scaler']\n",
    "pca    = pipeline.named_steps['pca']\n",
    "model  = pipeline.named_steps['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866e9ad",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e904c8",
   "metadata": {},
   "source": [
    "#### Task 3: Extracting data and pre-processing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03907377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract feature columns used in training ---\n",
    "feature_cols = scaler.feature_names_in_\n",
    "\n",
    "# --- Split datasets into features (X) and target (y) ---\n",
    "X_train   = train_165_df[feature_cols]\n",
    "y_train   = train_165_df[\"groups\"].astype(int)\n",
    "\n",
    "X_test1   = test1_df[feature_cols]\n",
    "y_test1   = test1_df[\"groups\"].astype(int)\n",
    "\n",
    "X_test2   = test2_df[feature_cols]\n",
    "y_test2   = test2_df[\"groups\"].astype(int)\n",
    "\n",
    "X_unknown = unknown_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd31919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled    = scaler.transform(X_train)\n",
    "X_test1_scaled    = scaler.transform(X_test1)\n",
    "X_test2_scaled    = scaler.transform(X_test2)\n",
    "X_unknown_scaled  = scaler.transform(X_unknown)\n",
    "\n",
    "X_train_pca    = pca.transform(X_train_scaled)\n",
    "X_test1_pca    = pca.transform(X_test1_scaled)\n",
    "X_test2_pca    = pca.transform(X_test2_scaled)\n",
    "X_unknown_pca  = pca.transform(X_unknown_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b099f6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab36c46",
   "metadata": {},
   "source": [
    "#### Task 4: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95b785b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This 'Pipeline' has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\svm\\_base.py:831\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[1;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when probability=False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\pipeline.py:78\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:43\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:34\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n",
      "\u001b[1;31mAttributeError\u001b[0m: This 'SVC' has no attribute 'predict_proba'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Predict class probabilities ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m proba_test1   \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X_test1)\n\u001b[0;32m      3\u001b[0m proba_test2   \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict_proba(X_test2)\n\u001b[0;32m      4\u001b[0m proba_unknown \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict_proba(X_unknown)\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:43\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m         out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m# for instance when monkeypatching.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\UserPhD\\anaconda3\\envs\\predikce_env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:34\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     32\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: This 'Pipeline' has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# --- Predict class probabilities ---\n",
    "proba_test1   = pipeline.predict_proba(X_test1)\n",
    "proba_test2   = pipeline.predict_proba(X_test2)\n",
    "proba_unknown = pipeline.predict_proba(X_unknown)\n",
    "\n",
    "# --- Predict class labels ---\n",
    "y_test1_pred   = pipeline.predict(X_test1)\n",
    "y_test2_pred   = pipeline.predict(X_test2)\n",
    "y_unknown_pred = pipeline.predict(X_unknown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79319b4e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c0469",
   "metadata": {},
   "source": [
    "#### Task 5: Adjusting the decision threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb373ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Decision scores (distance to boundary) ---\n",
    "scores_train   = pipeline.decision_function(X_train)\n",
    "scores_test1   = pipeline.decision_function(X_test1)\n",
    "scores_test2   = pipeline.decision_function(X_test2)\n",
    "scores_unknown = pipeline.decision_function(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating initial predictions with default threshold\n",
    "y_unk_orig   = (scores_unknown > 0).astype(int)\n",
    "y_train_orig   = (scores_train > 0).astype(int)\n",
    "y_test2_orig  = (scores_test2  > 0).astype(int)\n",
    "y_test1_orig  = (scores_test1  > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3ac3f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e886be",
   "metadata": {},
   "source": [
    "#### Task 6: Evaluation and visualization of the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate meshgrid and decision surface\n",
    "plt.figure(figsize=(10,8))\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca [:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca [:, 1].min() - 1, X_train_pca [:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = model.decision_function(grid).reshape(xx.shape)\n",
    "\n",
    "# Define custom colormaps\n",
    "cmap_train  = mcolors.ListedColormap(['#fb9a99', '#a6cee3'])  # Light colors for train data\n",
    "cmap_unknown =  mcolors.ListedColormap(['#e31a1c', '#1f78b4'])\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.2, cmap=plt.cm.coolwarm_r)# Decision boundary\n",
    "plt.contour(xx, yy, Z, levels=[0], colors='k', linewidths=1) #levels are responsible for the threshold\n",
    "\n",
    "# Scatter plot: training data\n",
    "plt.scatter(X_train_pca [:, 0], X_train_pca [:, 1],\n",
    "    c=y_train, cmap=cmap_train, edgecolors='k', s=80, label='Train')\n",
    "\n",
    "# Scatter plot: test2 data\n",
    "plt.scatter(X_test2_pca [:, 0], X_test2_pca [:, 1],\n",
    "    c=y_test2, cmap=cmap_train , marker=\"D\", edgecolors='k', s=80, label='Test 2')\n",
    "\n",
    "# Scatter plot: unknown data\n",
    "plt.scatter(X_unknown_pca[:, 0], X_unknown_pca[:, 1],\n",
    "    c=y_unknown_pred, cmap=cmap_unknown, edgecolors='k', s=80, label='Unknown')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Polynomial SVM Decision Boundary at Threshold = 0')\n",
    "\n",
    "# Create legend\n",
    "patch0_train = mpatches.Patch(color='#a6cee3', label='Training: good mRNA quality')\n",
    "patch1_train = mpatches.Patch(color='#fb9a99', label='Training: poor mRNA quality')\n",
    "patch0_test = mpatches.Patch(color='#a6cee3', label='Test 2: good mRNA quality')\n",
    "patch1_test = mpatches.Patch(color='#fb9a99', label='Test 2: poor mRNA quality')\n",
    "patch0_unknown = mpatches.Patch(color='#1f78b4', label='Unknowns: good mRNA quality')\n",
    "patch1_unknown = mpatches.Patch(color='#e31a1c', label='Unknowns: poor mRNA quality')\n",
    "\n",
    "plt.legend(handles=[patch0_train, patch1_train, patch0_test, patch1_test, patch0_unknown, patch1_unknown], loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c697615",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd50052",
   "metadata": {},
   "source": [
    "#### Task 7: Key hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2995d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key hyperparameters\n",
    "print(\"\\n=== Key hyperparameters ===\")\n",
    "print(f\"Kernel: {model.kernel}\")\n",
    "print(f\"Degree: {model.degree}\")\n",
    "print(f\"C:      {model.C}\")\n",
    "print(f\"Gamma:  {model.gamma}\")\n",
    "print(f\"Coef0:  {model.coef0}\")\n",
    "print(f\"Total support vectors: {model.support_vectors_.shape[0]}\")\n",
    "\n",
    "print(\"\\n=== Threshold-dependent parameters ===\")\n",
    "print(f\"Original threshold: 0\")\n",
    "pos_orig = np.sum(y_unk_orig == 1)\n",
    "neg_orig = np.sum(y_unk_orig == 0)\n",
    "print(f\"\\nNumber of samples classified as OK (1) at threshold 0:  {pos_orig}\")\n",
    "print(f\"Number of samples classified as altered (0) at threshold 0: {neg_orig}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9403b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ccc51",
   "metadata": {},
   "source": [
    "#### Task 8: Analyzing threshold ranges without changing FNR and FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data score range\n",
    "max_neg_score_test2 = scores_test2[y_test2 == 0].max()\n",
    "min_pos_score_test2 = scores_test2[y_test2 == 1].min()\n",
    "\n",
    "# Threshold range without altering test predictions, FNR, or FPR\n",
    "print(f\"↔️ Threshold range preserving test predictions, FNR, and FPR \"\n",
    "      f\"({max_neg_score_test2:.2f}, {min_pos_score_test2:.2f}) \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6ae7d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe6938",
   "metadata": {},
   "source": [
    "#### Task 9: Determining FNR and threshold ranges for reliable predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNR values to test\n",
    "fnr_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dfa1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnr in fnr_list:\n",
    "    print(f\"\\n{'='*40}\\nFNR: {fnr}%\")\n",
    "\n",
    "    test_samples = samples[\"test2\"]\n",
    "    train_samples = samples[\"train_165\"]\n",
    "    unknown_samples = samples[\"unknown\"]\n",
    "\n",
    "    # Calculating threshold from test scores for poor-quality samples\n",
    "    bad_scores_test2 = scores_test2[y_test2 == 0]\n",
    "    threshold_dynamic2 = np.percentile(bad_scores_test2, 100 - fnr)\n",
    "    print(f\"Calculated threshold based on test data for {fnr}% FNR: {threshold_dynamic2:.2f}\")\n",
    "\n",
    "    # Updating predictions based on dynamic threshold\n",
    "    y_train_adj = (scores_train > threshold_dynamic2).astype(int)\n",
    "    y_test1_adj = (scores_test1 > threshold_dynamic2).astype(int)\n",
    "    y_test2_adj = (scores_test2 > threshold_dynamic2).astype(int)\n",
    "    y_unk_adj = (scores_unknown > threshold_dynamic2).astype(int)\n",
    "\n",
    "    plt.hist(scores_test2[y_test2 == 0], bins=20, alpha=0.5, label=\"Poor samples\", color=\"#fb9a99\")\n",
    "    plt.hist(scores_test2[y_test2 == 1], bins=20, alpha=0.5, label=\"Good samples\", color=\"#a6cee3\")\n",
    "    plt.axvline(x=0, color='k', linestyle='--', label='Original threshold')\n",
    "    plt.axvline(x=threshold_dynamic2, color='r', linestyle='--', label='Adjusted threshold')\n",
    "    plt.legend()\n",
    "    plt.title(\"Decision scores distribution — Test set 2\")\n",
    "    plt.xlabel(\"Decision score\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    # Plotting decision boundary at adjusted threshold\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f\"SVM Threshold for Decision Boundary at FNR {fnr}% (Threshold={threshold_dynamic2:.2f})\")\n",
    "    x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "    y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.decision_function(grid).reshape(xx.shape)\n",
    "\n",
    "    #  Define custom colormaps for plotting\n",
    "    cmap_train = mcolors.ListedColormap(['#fb9a99', '#a6cee3'])  # Light colors for train data\n",
    "    cmap_unknown =  mcolors.ListedColormap(['#e31a1c', '#1f78b4'])\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.2, cmap=plt.cm.coolwarm_r) # Decision boundary\n",
    "    plt.contour(xx, yy, Z, levels=[threshold_dynamic2], colors='k', linewidths=1) #levels are responsible for the threshold\n",
    "\n",
    "    # Scatter plot: training data\n",
    "    plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1],\n",
    "        c=y_train, cmap=cmap_train, marker='x', s=80, label='Train')\n",
    "\n",
    "     # Scatter plot: training data\n",
    "    plt.scatter(X_test2_pca[:, 0], X_test2_pca[:, 1],\n",
    "        c=y_test2_adj, cmap=cmap_train, marker='D', s=80, label='Test2')\n",
    "   \n",
    "    # Scatter plot: unknown data\n",
    "    plt.scatter(X_unknown_pca[:, 0], X_unknown_pca[:, 1],\n",
    "        c=y_unk_adj, cmap=cmap_unknown, edgecolors='k', s=80, label='Unknowns')\n",
    "\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "\n",
    "    # Legend patches\n",
    "    patch0_train = mpatches.Patch(color='#a6cee3', label='Training: good mRNA quality')\n",
    "    patch1_train = mpatches.Patch(color='#fb9a99', label='Training: poor mRNA quality')\n",
    "    patch0_test = mpatches.Patch(color='#a6cee3', label='Test 2 (diamonts): good mRNA quality')\n",
    "    patch1_test = mpatches.Patch(color='#fb9a99', label='Test 2 (diamonts): poor mRNA quality')\n",
    "    patch0_unknown = mpatches.Patch(color='#1f78b4', label='Unknowns: good mRNA quality')\n",
    "    patch1_unknown = mpatches.Patch(color='#e31a1c', label='Unknowns: poor mRNA quality')\n",
    "\n",
    "    plt.legend(handles=[patch0_train, patch1_train, patch0_test, patch1_test, patch0_unknown, patch1_unknown], loc='lower left')\n",
    "    plt.show()\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    # UNKNOWN data (we are interested in)\n",
    "    good_unk_idx = np.where(y_unk_adj == 1)[0]\n",
    "    bad_unk_idx = np.where(y_unk_adj == 0)[0]\n",
    "    changed_unk_idx = np.where(y_unk_adj != y_unk_orig)[0]\n",
    "\n",
    "    # UNKNOWN data\n",
    "    if len(changed_unk_idx) > 0:\n",
    "        if isinstance(unknown_samples, pd.Series):\n",
    "            changed_unk_samples = unknown_samples.iloc[changed_unk_idx].tolist()\n",
    "        else:\n",
    "            changed_unk_samples = unknown_samples[changed_unk_idx].tolist()    \n",
    "\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n[Unknown Data]\")\n",
    "    print(f\"Number of samples classified as OK (1): {len(good_unk_idx)}\")\n",
    "    print(f\"Number of samples classified as altered (0): {len(bad_unk_idx)}\")\n",
    "    print(f\"Number of samples with changed classification compared to the threshold 0: {len(changed_unk_idx)}\")\n",
    "\n",
    "    # Save predictions to CSV in the notebook’s output folder\n",
    "    output_df = pd.DataFrame({\n",
    "        'sample': unknown_samples,\n",
    "        f'predicted_class_FNR{fnr}': y_unk_adj\n",
    "    })\n",
    "    filename = NB_OUTPUT / f\"unknown_predictions_FNR{fnr}.csv\"\n",
    "    output_df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Unknown data exported to: {filename}\")\n",
    "\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------------------\n",
    "    # TRAIN data (change control)\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n[Original Train Data - Change Control]\")\n",
    "    changed_train_idx = np.where(y_train_adj != y_train_orig)[0]\n",
    "    if len(changed_train_idx) > 0:\n",
    "        print(f\"⚠️ {len(changed_train_idx)} training samples changed classification compared to original settings!\")\n",
    "        changed_train_samples = train_samples[changed_train_idx].tolist()\n",
    "        print(\"Changed samples:\")\n",
    "        print(\", \".join(map(str, changed_train_samples)))\n",
    "    else:\n",
    "        print(\"No classification changes compared to original settings.\")\n",
    "    \n",
    "   \n",
    "    #-----------------------------------------------------------------------------------------------------------------------\n",
    "     # TEST data\n",
    "    good_test_idx = np.where(y_test2_adj == 1)[0]\n",
    "    bad_test_idx = np.where(y_test2_adj == 0)[0]\n",
    "    changed_test_idx = np.where(y_test2_adj != y_test2_orig)[0]\n",
    "\n",
    "    if isinstance(test_samples, pd.Series):\n",
    "        good_test_samples = test_samples.iloc[good_test_idx].tolist()\n",
    "        bad_test_samples = test_samples.iloc[bad_test_idx].tolist()\n",
    "        changed_test_samples = test_samples.iloc[changed_test_idx].tolist()\n",
    "    else:\n",
    "        good_test_samples = test_samples[good_test_idx].tolist()\n",
    "        bad_test_samples = test_samples[bad_test_idx].tolist()\n",
    "        changed_test_samples = test_samples[changed_test_idx].tolist()\n",
    "\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n[Test 2 Data]\")\n",
    "    print(f\"Number of samples classified as OK (1): {len(good_test_idx)}\")\n",
    "    print(\", \".join(map(str, good_test_samples)) if good_test_samples else \"None samples\")\n",
    "    \n",
    "    print(f\"\\nNumber of samples classified as altered (0): {len(bad_test_idx)}\")\n",
    "    print(\", \".join(map(str, bad_test_samples)) if bad_test_samples else \"None samples\")\n",
    "\n",
    "    print(f\"\\nNumber of samples with changed classification compared to the threshold 0: {len(changed_test_idx)}\")\n",
    "    if changed_test_samples:\n",
    "        print(\", \".join(map(str, changed_test_samples)))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36990384",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a611025",
   "metadata": {},
   "source": [
    "#### Task 10: Selecting the decision threshold based on FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2096ad",
   "metadata": {},
   "source": [
    "ℹ️ Rationale for Adjusting the False Negative Rate (FNR) in the Application\n",
    "\n",
    "Adjusting the FNR shifts the decision threshold toward the OK class, allowing a small fraction of samples with borderline altered gene expression to be classified as good quality samples. Because our altered-expression criteria are very stringent, these marginal cases pose minimal risk.\n",
    "\n",
    "FNR = 0%**: The strictest setting. The decision threshold sits at the extreme edge of the altered distribution, so all other samples, even borderline cases, are classified as OK.\n",
    "\n",
    "Maximum FNR = 9%: The highest FNR that still maintains 100% specificity on the training set (i.e., no altered training sample is misclassified).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab80f86",
   "metadata": {},
   "source": [
    "Our unknown samples were of good quality and were mixed with test samples of poorer quality. Therefore, our hypothesis is to maximize the number of “good” samples correctly identified while ensuring “poor” samples are accurately detected. Based on this, the optimal FNR threshold for our unknown samples was set to 5% (build-in example).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca82c1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d80bf",
   "metadata": {},
   "source": [
    "#### Task 11: Built-in data and final outcome from EDTA_QC testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d822e0",
   "metadata": {},
   "source": [
    "We all know that even the best-intentioned EDTA blood draws can sit too long in the tube and quietly distort mRNA levels. Described EDTA QC tool lets you catch those hidden QC failures before they sneak into your biological analyses. To illustrate its use, we applied our EDTA QC application to an already published dataset. Our built-in example uses the data from Slyskova et al. (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b5718",
   "metadata": {},
   "source": [
    "In that study, mRNA expression was measured in four cohorts: healthy volunteers, pre-operative colorectal carcinoma patients, early post-operative patients, and six-month survivors—using a rigorously validated cancer-marker panel. Those markers successfully grouped most samples into two clusters (diseased vs. recovered/healthy), but a few “strayed” into the wrong cluster. Unfortunately, those outliers all had sufficiently high RIN scores, so standard RNA-integrity filters provided no reason to exclude them. That’s where our application comes in.\n",
    "\n",
    "We developed an EDTA QC marker panel capable of distinguishing “good” quality samples from those whose mRNA expression had been altered by suboptimal handling.\n",
    "\n",
    "In Figure 1, you can see a PCA plot showing two clusters corresponding to the four patient cohorts; however, some samples overlap, making the separation somewhat fuzzy. This is the PCA plot before EDTA QC filtering.\n",
    "\n",
    "\n",
    "![Before-cleaning](./before.jpg)\n",
    "\n",
    "In Figure 2, the same PCA plot is shown after EDTA QC flagged and removed suspect samples. The false negative rate was set to 5%. Under this condition, one-third of the samples (24/69) were excluded because they were impaired during EDTA tube handling.\n",
    "\n",
    "![After cleaning](./after.jpg)\n",
    "\n",
    "Conclusion\n",
    "When the EDTA QC markers were used to clean this dataset:\n",
    "\n",
    "    The cancer-marker panel achieved even higher specificity than originally reported (by removing potential bias introduced by EDTA tubes).\n",
    "\n",
    "    It became clear why dedicated tubes and strict handling are essential for maintaining stable gene expression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc3075",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911ba5b",
   "metadata": {},
   "source": [
    "Go to application via terminal: streamlit run src/app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predikce_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
